/*
* Intel VCA Software Stack (VCASS)
*
* Copyright(c) 2015-2017 Intel Corporation.
*
* This program is free software; you can redistribute it and/or modify
* it under the terms of the GNU General Public License, version 2, as
* published by the Free Software Foundation.
*
* This program is distributed in the hope that it will be useful, but
* WITHOUT ANY WARRANTY; without even the implied warranty of
* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
* General Public License for more details.
*
* The full GNU General Public License is included in this distribution in
* the file called "COPYING".
*
* Intel PLX87XX VCA PCIe driver
*/
#include <linux/module.h>
#include <linux/pci.h>
#include <linux/poll.h>
#include <linux/version.h>
#include <linux/suspend.h>
#include <linux/kthread.h>
#include <linux/delay.h>
#include <linux/sched.h>
#include <linux/proc_fs.h>
#include <linux/wait.h>
#include <linux/uaccess.h>

#include "../plx87xx_minidriver/plx_device.h"

#define GPIO_REG 0x624
#define VIRTUAL_DBG_SW_REG 0xA30
#define MARGIN_TIME          8
#define POWER_OFF_HOLD_TIME   (5200 + (MARGIN_TIME))
#define POWER_OFF_PULSE_TIME  (200 + (MARGIN_TIME))
#define RESET_PULSE_TIME	(16 + (MARGIN_TIME))
#define GPIO_DEF_WAIT_TIME	(500 + (MARGIN_TIME))
#define VCA_DMA_LINK_NAME "dma_device"

#define PV_SIGIGNATURE	0x0
#define PV_VERSION		0x4
#define PV_ROOTBUS		0x8
#define PV_ROOTPORT		0xc
#define PV_DMABUS		0x10

bool kvm_check_guest(void)
{
	unsigned int eax, ebx, ecx, edx;
	char s[12];
	unsigned int *i;

	/* KVM_CPUID_SIGNATURE */
	eax = 0x40000000;
	ebx = ecx = edx = 0;

	asm volatile ("cpuid"
		: "+a"(eax), "=b"(ebx), "=c"(ecx), "=d"(edx)
		:
		: "cc", "memory");
	i = (unsigned int *)s;
	i[0] = ebx;
	i[1] = ecx;
	i[2] = edx;

	return !strncmp(s, "KVMKVMKVM", strlen("KVMKVMKVM"));
}

static const u32 plx_reset_bits[2][3] = {
	{
		PLX_VV_CPU0_RESET_BIT,
		PLX_VV_CPU1_RESET_BIT,
		PLX_VV_CPU2_RESET_BIT
	},
		{
			PLX_MV_CPU0_RESET_BIT,
			PLX_MV_CPU1_RESET_BIT,
			PLX_MV_CPU2_RESET_BIT
		}
};

const u32 plx_reset_bits_vcga[2] = {
	PLX_VCGA_CPU0_RESET_BIT,
	PLX_VCGA_CPU1_RESET_BIT
};

const u32 plx_power_button_bits[3] = {
	PLX_CPU0_POWER_BIT,
	PLX_CPU1_POWER_BIT,
	PLX_CPU2_POWER_BIT
};

const u32 plx_bios_rcv_bits[3] = {
	PLX_BIOS_RCV_MODE_CPU0,
	PLX_BIOS_RCV_MODE_CPU1,
	PLX_BIOS_RCV_MODE_CPU2
};

const u32 plx_bios_rcv_bits_vcga[2] = {
	PLX_VCGA_BIOS_RCV_MODE_CPU0,
	PLX_VCGA_BIOS_RCV_MODE_CPU1
};

extern struct plx_device * plx_contexts[MAX_VCA_CARDS][MAX_VCA_CARD_CPUS];

#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 37)
static const char plx_driver_name[] = "plx87xx_vca";
#else
static char plx_driver_name[] = "plx87xx_vca";
#endif

static const struct pci_device_id plx_pci_tbl[] = {
{ PCI_DEVICE(PCI_VENDOR_ID_INTEL, INTEL_VCA_PCI_NODE0_ID) },
{ PCI_DEVICE(PCI_VENDOR_ID_INTEL, INTEL_VCA_PCI_NODE1_ID) },
{ PCI_DEVICE(PCI_VENDOR_ID_INTEL, INTEL_VCA_PCI_NODE2_ID) },
{ PCI_DEVICE(PCI_VENDOR_ID_INTEL, INTEL_VCA_DMA_ID) },

/* required last entry */
{ 0, }
};

MODULE_DEVICE_TABLE(pci, plx_pci_tbl);

/* ID allocator for VCA devices */
static struct ida g_plx_ida;

struct plx_device * plx_contexts[MAX_VCA_CARDS][MAX_VCA_CARD_CPUS]
	= { { 0 } };
enum subsystem_id {
	SUBSYSTEM_ID_VV_POC = 0x1000,
	SUBSYSTEM_ID_VV_FAB1 = 0x1001,
	SUBSYSTEM_ID_VV_FAB2 = 0x1002,
	SUBSYSTEM_ID_MV_FAB1 = 0x1004,
	SUBSYSTEM_ID_VCAA_FAB1 = 0x1006,
	SUBSYSTEM_ID_FPGA_FAB1 = 0x1008,
	SUBSYSTEM_ID_VCGA_FAB1 = 0x1009,
};
/**
* plx_mmio_read - read from an MMIO register.
* @mw: MMIO register base virtual address.
* @offset: register offset.
*
* RETURNS: register value.
*/
static inline u32 plx_mmio_read(struct vca_mw *mw, u32 offset)
{
	return ioread32(mw->va + offset);
}

/**
* plx_mmio_write - write to an MMIO register.
* @mw: MMIO register base virtual address.
* @val: the data value to put into the register
* @offset: register offset.
*
* RETURNS: none.
*/
static inline void
plx_mmio_write(struct vca_mw *mw, u32 val, u32 offset)
{
	iowrite32(val, mw->va + offset);
}

static inline u32 plx_link_mmio_read(struct plx_device *xdev, u32 offset)
{
	struct vca_mw *mw = &xdev->mmio;
	return ioread32(mw->va + xdev->mmio_link_offset + offset);
}

static inline void
plx_link_mmio_write(struct plx_device *xdev, u32 val, u32 offset)
{
	struct vca_mw *mw = &xdev->mmio;

	iowrite32(val, mw->va + xdev->mmio_link_offset + offset);
}

/**
* plx_a_lut_disable() - disable alut
* @xdev: pointer to plx_device instance
*
* */
void plx_a_lut_disable(struct plx_device *xdev)
{
	plx_mmio_write(&xdev->mmio, 0, xdev->reg_base + PLX_A_LUT_CONTROL);
}

u32 plx_find_rootinfo(struct pci_dev *pdev)
{
	bool kvm;
	u32 ret;
	u32 rb, rp;
	int len;
	void *mmio, *p;
	struct pci_dev *root_port;
	u8 root_complex_bus_num;

	kvm = kvm_check_guest();
	if (kvm) {
		/* TODO: check signature */
		len = pci_resource_len(pdev, 0) / 2;

		mmio = pci_iomap(pdev, 0, ~0UL);
		p = mmio + len;

		rb = readl(p + PV_ROOTBUS);
		rp = readl(p + PV_ROOTPORT);

		ret = rb << 16 | rp;
		pci_iounmap(pdev, mmio);
		return ret;
	}

	rootinfo = plx_find_rootinfo(pdev);
	if (rootinfo == 0) {
		dev_err(&pdev->dev, "can't find PCIe root information\n");
		return -ENXIO;
	}
	root_complex_bus_num = plx_find_root_complex_bus_num(pdev);

	ret = root_complex_bus_num << 16 | PCI_DEVID(root_port->bus->number, root_port->devfn);
	return ret;
}

u32 plx_find_dma_bus_number(struct pci_dev *pdev)
{
	bool kvm;
	u32 ret = 0;
	u32 db;
	int len;
	void *mmio, *p;

	kvm = kvm_check_guest();
	if (kvm) {
		/* TODO: check signature */
		len = pci_resource_len(pdev, 0) / 2;

		mmio = pci_iomap(pdev, 0, ~0UL);
		p = mmio + len;

		db = readl(p + PV_DMABUS);

		ret = db;
		pci_iounmap(pdev, mmio);
		return ret;
	}

	return ret;
}

/*
* plx_find_root_port - find root port which plx chip connects to
*
* @pdev: The PCIe device
*
* RETURNS: struct pci_dev *, NULL on don't find a root port device which will
*          never happen.
*/
static struct pci_dev *
plx_find_root_port(struct pci_dev *pdev)
{
	for (pdev = pdev->bus->self;
		pdev && (pci_pcie_type(pdev) != PCI_EXP_TYPE_ROOT_PORT);
		pdev = pdev->bus->self)
		;
	return pdev;
}

/*
* plx_find_root_complex_bus_num - find root complex bus number for a pdev
*
* @pdev: The PCIe device
*
* RETURNS: The root complex bus number
*/
static u8
plx_find_root_complex_bus_num(struct pci_dev *pdev)
{
	struct pci_bus *bus = pdev->bus;

	while (bus->parent)
		bus = bus->parent;

	return bus->number;
}

/*
* plx_rid_lut - construct RID LUT value
*
* @root_port_bus: bus number of root port device
* @root_port_dev: device number of root port device
* @root_complex_bus: bus number of root complex device
* @root_complex_dev: device number of root complex device
*
* RETURNS: RID LUT
*/
static inline u32
plx_rid_lut(u8 root_port_bus, u8 root_port_dev,
	u8 root_complex_bus, u8 root_complex_dev)
{
	return ((root_port_bus << 24) | ((root_port_dev & 0x0f) << 19) |
		(root_complex_bus << 8) | ((root_complex_dev & 0x0f) << 3) |
		PLX_RID_LUT_ENABLE);
}

/*
* plx_rid_lut_dma - construct RID LUT value for DMA
*
* @dma_bus: bus number of DMA device
*
* RETURNS: RID LUT
*/
static inline u32 plx_rid_lut_dma(u8 dma_bus)
{
	return (dma_bus << 8) | PLX_RID_LUT_ENABLE_1;
}

/*
* plx_program_rid_lut - program RID LUT
*
* @xdev: pointer to plx_device instance
* @pdev: The PCIe device
*
* RETURNS: 0 on success and errno on failure
*/
static int
plx_program_rid_lut(struct plx_device *xdev, struct pci_dev *pdev)
{
	u32 rid_lut;
	u32 virtual_rid_offset, link_rid_offset;
	u32 rootinfo;
	u8 root_bus, rp_bus, rp_devfn;

	if (xdev->port_id == 0) {
		// NT0
		virtual_rid_offset = PLX_NT0_RID_LUT_VIRTUAL_OFFSET;
		link_rid_offset = PLX_NT0_RID_LUT_LINK_OFFSET;
	}
	else {
		// NT1
		virtual_rid_offset = PLX_NT1_RID_LUT_VIRTUAL_OFFSET;
		link_rid_offset = PLX_NT1_RID_LUT_LINK_OFFSET;
	}

	root_port = plx_find_root_port(pdev);
	if (!root_port) {
		dev_err(&pdev->dev, "can't find root port\n");
		return -ENXIO;
	}
	root_complex_bus_num = plx_find_root_complex_bus_num(pdev);
	rid_lut = plx_rid_lut(
		root_port->bus->number,
		PCI_SLOT(root_port->devfn),
		root_complex_bus_num,
		0);
	dev_info(&xdev->pdev->dev, "DMA port bus: 0x%X, port: 0x%X\n", root_port->bus->number, PCI_SLOT(root_port->devfn));

	if (xdev->link_side) {
		plx_mmio_write(&xdev->mmio, rid_lut, link_rid_offset);
	}
	else {
		plx_mmio_write(&xdev->mmio, rid_lut, virtual_rid_offset);
	}
	return 0;
}

/* plx_get_a_lut_entry_offset - calculate an offset to a given A-LUT entry
* in A-LUT array. The offset is to a first subarray only- next subarrays
* offsets needs to be calculated by own; function covers a case of
* A-LUT table divided to two arrays
*
* @idx- index of an A-LUT entry
*
* RETURNS: offset of a given A-LUT entry, starting from the beginning of
* a first array
*/
static inline unsigned int plx_get_a_lut_entry_offset(unsigned int idx)
{
	unsigned int array_offset = (idx >= PLX_A_LUT_MAX_ARRAY) ? PLX_A_LUT_ARRAY_OFFSET : 0;
	return array_offset + (idx % PLX_A_LUT_MAX_ARRAY) * sizeof(u32);
}

/*
* plx_a_lut_clear - clear A-LUT entries
*
* @xdev: pointer to plx_device instance
* @offset: offset of A-LUT array
*
* RETURNS: nothing
*/
void
plx_a_lut_clear(struct plx_device* xdev, u32 offset)
{
	int i;
	unsigned int entry_offset;

	plx_alm_reset(&xdev->a_lut_manager, xdev->pdev);

	for (i = 0; i<xdev->a_lut_manager.segments_num; i++)
	{
		entry_offset = plx_get_a_lut_entry_offset(i) + offset;

		plx_mmio_write(&xdev->mmio, 0, entry_offset +
			PLX_A_LUT_PERMISSION_SUBARRAY_OFFSET);
		plx_mmio_write(&xdev->mmio, 0, entry_offset +
			PLX_A_LUT_HIGHER_RE_MAP_SUBARRAY_OFFSET);
		plx_mmio_write(&xdev->mmio, 0, entry_offset +
			PLX_A_LUT_LOWER_RE_MAP_SUBARRAY_OFFSET);
	}
}

/*
* _plx_configure_a_lut - enable A-LUT
*
* @xdev: pointer to plx_device instance
* @pdev: The PCIe device
*
* RETURNS: 0 on success and errno on failure
*/
static int
_plx_a_lut_enable(struct plx_device *xdev, struct pci_dev *pdev)
{
	spin_lock(&xdev->alm_lock);
	plx_a_lut_disable(xdev);
	plx_a_lut_clear(xdev, xdev->a_lut_array_base);

	if (xdev->a_lut_peer)
		plx_mmio_write(&xdev->mmio, PLX_A_LUT_ENABLE,
			xdev->reg_base + PLX_A_LUT_CONTROL);

	spin_unlock(&xdev->alm_lock);

	return 0;
}

/*
* plx_a_lut_peer_enable - enable A-LUT for peer
*
* @xdev: pointer to plx_device instance
*
* RETURNS: nothing
*/
void
plx_a_lut_peer_enable(struct plx_device *xdev)
{
	dev_dbg(&xdev->pdev->dev, "%s Enable A-LUT for peer reg peeer base %x, \n",
		__func__, xdev->reg_base_peer);

	plx_mmio_write(&xdev->mmio, PLX_A_LUT_ENABLE,
		xdev->reg_base_peer + PLX_A_LUT_CONTROL);
}

static u32 _plx_get_reg_base(u32 link_side, u32 port_id)
{
	return 0x3E000 - port_id * 0x2000 + link_side * 0x1000;
}

/*
* plx_check_eeprom - Check EEPROM validity and content CRC
*
* @xdev: pointer to plx_device instance
*
* RETURNS: 0 on success and errno on failure
*/
int plx_check_eeprom(struct plx_device *xdev)
{
	u32 val;
	u32 crc;

	val = plx_mmio_read(&xdev->mmio, PLX_EEP_STATUS_CONTROL);

	switch ((val & PLX_EEP_EEPPRSNT_MASK) >> PLX_EEP_EEPPRSNT_SHIFT) {
	case PLX_EEP_EEPPRSNT_NOT_PRESENT:
		dev_err(&xdev->pdev->dev, "EEPROM not present\n");
		return -EIO;
	case PLX_EEP_EEPRRSNT_SIGNATURE_OK:
		dev_dbg(&xdev->pdev->dev, "EEPROM present, signature valid\n");
		break;
	case PLX_EEP_EEPRRSNT_SIGNATURE_FAIL:
		dev_err(&xdev->pdev->dev, "EEPROM present, signature fail\n");
		return -EIO;
	default:
		dev_err(&xdev->pdev->dev, "Unknown EEPROM status\n");
		return -EIO;
	}

	crc = plx_mmio_read(&xdev->mmio, PLX_EEP_CRC);
	dev_info(&xdev->pdev->dev, "EEPROM CRC: 0x%08x\n", crc);

	if (val & PLX_EEP_EEPCRC_ERR_MASK) {
		dev_err(&xdev->pdev->dev, "EEPROM CRC check fail");
		return -EIO;
	}
	else {
		dev_info(&xdev->pdev->dev, "EEPROM CRC check OK\n");
	}

	return 0;
}

/*
* plx_hw_init - Initialize any hardware specific information
*
* @xdev: pointer to plx_device instance
* @pdev: The PCIe device
*
* RETURNS: 0 on success and errno on failure
*/
int plx_hw_init(struct plx_device *xdev, struct pci_dev *pdev)
{
	u32 val;
	int rc;
	unsigned alut_segments = 0;
	unsigned alut_ports = 0;
	u32 const rid_lut = plx_rid_lut_dma(pdev->bus->parent->parent->number);

	spin_lock_init(&xdev->alm_lock);
	dev_info(&pdev->dev, "Device: %04x\n", xdev->pdev->device);
	switch (xdev->pdev->device) {

	case 0x2952:	xdev->port_id = 0; xdev->link_side = 0; break;
	case 0x2954:	xdev->port_id = 0; xdev->link_side = 0; break;
	case 0x2955:	xdev->port_id = 1; xdev->link_side = 0; break;
	case 0x2956:	xdev->port_id = 0; xdev->link_side = 0; break;
	case 0x2958:	xdev->port_id = 0; xdev->link_side = 1; break;
	case 0x2959:	xdev->port_id = 1; xdev->link_side = 1; break;
	case 0x295a:	xdev->port_id = 0; xdev->link_side = 1; break;
	default:dev_err(&pdev->dev, "Unsupporter device %x\n", xdev->pdev->device); return -ENODEV;
	}
	xdev->reg_base = _plx_get_reg_base(xdev->link_side, xdev->port_id);
	xdev->reg_base_peer = _plx_get_reg_base(!xdev->link_side, xdev->port_id);

	xdev->a_lut = false;
	xdev->a_lut_peer = false;
#ifdef VCA_ALUT_CARD_SIDE
	if (xdev->link_side) {
		xdev->a_lut = true;
	}
	else {
		xdev->a_lut_peer = true;
	}
#endif
#ifdef VCA_ALUT_HOST_SIDE
	if (xdev->link_side) {
		xdev->a_lut_peer = true;
	}
	else {
		xdev->a_lut = true;
	}
#endif

	if (!xdev->link_side) {
		rc = plx_check_eeprom(xdev);
		if (rc)
			return rc;
	}

	if (xdev->link_side) {
		xdev->intr_reg_base = 0x10;
	}
	else {
		xdev->peer_intr_reg_base = 0x10;
	}

	/* Calculate A-LUT segments numbers */
	val = plx_link_mmio_read(xdev, PLX_VS0UPSTREAM);

	if (val & PLX_ALUT_NT0_PORT_ENABLE) {
		++alut_ports;
	}
	if (val & PLX_ALUT_NT1_PORT_ENABLE) {
		++alut_ports;
	}

	if (!alut_ports) {
		dev_info(&xdev->pdev->dev, "Device 0x%x doesn't explicity identify VCA node. Assuming two NTBs. Switch to newer EEPROM\n",
			pdev->device);
		alut_ports = 2;
	}
	alut_segments = PLX_ALUT_SEGMENTS_NUM / alut_ports;

	if (alut_ports == 2) {
		if (!xdev->link_side)
			xdev->a_lut_array_base = (!xdev->port_id) ? 0x38000 : 0x3a000;
		else
			xdev->a_lut_array_base = (!xdev->port_id) ? 0x39000 : 0x3b000;
	}
	else {
		if (!xdev->link_side)
			xdev->a_lut_array_base = 0x38000;
		else
			xdev->a_lut_array_base = 0x3a000;
	}
	dev_info(&xdev->pdev->dev, "A-LUT array base port is %x\n",
		xdev->a_lut_array_base);

	rc = plx_program_rid_lut(xdev, pdev);
	if (rc) {
		dev_err(&pdev->dev, "can't program RID LUT: %d\n", rc);
		return rc;
	}


	plx_mmio_write(&xdev->mmio, rid_lut, xdev->reg_base + PLX_RID_LUT_2_3);
	dev_info(&xdev->pdev->dev, "DMA port bus: 0x%X, rid_lut: 0x%X\n", pdev->bus->parent->parent->number, rid_lut);

	rc = _plx_a_lut_enable(xdev, pdev);
	if (rc) {
		dev_err(&pdev->dev, "can't configure A LUT: %d\n", rc);
		return rc;
	}

	dev_info(&pdev->dev, "link_side %d reg_base 0x%x reg_base_peer 0x%x "\
		"port id 0x%x a_lut %d a_lut_peer %d\n", xdev->link_side,
		xdev->reg_base, xdev->reg_base_peer, xdev->port_id, xdev->a_lut,
		xdev->a_lut_peer);

	spin_lock(&xdev->alm_lock);

	rc = plx_alm_init(&xdev->a_lut_manager, xdev->pdev,
		alut_segments, xdev->aper.len);

	dev_info(&xdev->pdev->dev,
		"programmed a lut segment size to %llx num segments:%x alut_ports:%x\n",
		xdev->a_lut_manager.segment_size, xdev->a_lut_manager.segments_num,
		alut_ports);

	spin_unlock(&xdev->alm_lock);

	return rc;
}

/*
* plx_hw_deinit - Deinitialize any hardware
*
* @xdev: pointer to plx_device instance
*
* RETURNS: none.
*/
void
plx_hw_deinit(struct plx_device *xdev)
{
	spin_lock(&xdev->alm_lock);
	plx_alm_release(&xdev->a_lut_manager, xdev->pdev);
	spin_unlock(&xdev->alm_lock);
}

/**
* plx_add_lut_entry() - add entry to A LUT array
* @xdev: pointer to plx_device instance
* @addr: DMA address to access memory
*
* This function allows other side of NTB to access address @addr by adding
* a lookup entry to A LUT array.
*
* RETURNS: DMA addres to be used by the other side of NTB to access
* @dma_addr.
*
* */
int
plx_add_a_lut_entry(struct plx_device *xdev, dma_addr_t addr, size_t size,
	dma_addr_t *addr_out)
{
	u32 lower_re_map_offset;
	u32 higher_re_map_offset;
	u32 permission_offset = 0;
	u64 translation_mask = xdev->a_lut_manager.segment_size - 1;
	dma_addr_t addr_masked = addr & ~translation_mask;

	int i;
	int err;
	unsigned int entry_offset;
	u32 segments_num;
	u32 segment_id;
	u32 last_permission_reg = 0;

	spin_lock(&xdev->alm_lock);

	err = plx_alm_add_entry(&xdev->a_lut_manager, xdev->pdev, addr,
		size, &segment_id, &segments_num);
	if (err && err != -EEXIST) {
		goto failed;
	}

	if (err == 0) {
		for (i = segment_id; i < segment_id + segments_num; i++) {
			entry_offset = xdev->a_lut_array_base + plx_get_a_lut_entry_offset(i);

			lower_re_map_offset = entry_offset +
				PLX_A_LUT_LOWER_RE_MAP_SUBARRAY_OFFSET;
			higher_re_map_offset = entry_offset +
				PLX_A_LUT_HIGHER_RE_MAP_SUBARRAY_OFFSET;
			permission_offset = entry_offset +
				PLX_A_LUT_PERMISSION_SUBARRAY_OFFSET;

			plx_mmio_write(&xdev->mmio, (u32)(addr_masked >> 32),
				higher_re_map_offset);
			dev_dbg(&xdev->pdev->dev, "%s writing %x : %x\n",
				__func__, (u32)(addr_masked >> 32), higher_re_map_offset);
			plx_mmio_write(&xdev->mmio, (u32)(addr_masked), lower_re_map_offset);
			dev_dbg(&xdev->pdev->dev, "%s writing %x : %x\n",
				__func__, (u32)(addr_masked), lower_re_map_offset);
			wmb();
			plx_mmio_write(&xdev->mmio, PLX_A_LUT_PERMISSION_READ_ENABLE |
				PLX_A_LUT_PERMISSION_WRITE_ENABLE,
				permission_offset);
			dev_dbg(&xdev->pdev->dev, "%s writing %x : %x\n",
				__func__, PLX_A_LUT_PERMISSION_READ_ENABLE |
				PLX_A_LUT_PERMISSION_WRITE_ENABLE,
				permission_offset);
			last_permission_reg = permission_offset;
			addr_masked += xdev->a_lut_manager.segment_size;
		}

		mb();
		/*
		* This is barrier to check that last write to register end,
		* Check that hardware configuration finished.
		**/
		if (last_permission_reg)
			plx_mmio_read(&xdev->mmio, last_permission_reg);
	}
	spin_unlock(&xdev->alm_lock);

	*addr_out = segment_id * (u64)xdev->a_lut_manager.segment_size +
		(addr & translation_mask);

	dev_dbg(&xdev->pdev->dev,
		"%s map entry no %i original %llx translated %llx\n",
		__func__,
		segment_id,
		(u64)addr,
		(u64)*addr_out);

	return 0;

failed:
	spin_unlock(&xdev->alm_lock);
	return -ENOMEM;
}

/**
* plx_del_lut_entry() - delete entry from A LUT array
* @xdev: pointer to plx_device instance
* @addr: address in A-LUT segment
*
* This function allows other side of NTB to access address @addr by adding
* a lookup entry to A LUT array.
*
* RETURNS: none.
*
* */
void plx_del_a_lut_entry(struct plx_device *xdev, dma_addr_t addr)
{
	u32 segment_id = addr / (u64)xdev->a_lut_manager.segment_size;
	u32 segments_num = 0;
	u32 start_segment = 0;

	if (addr >= xdev->a_lut_manager.segments_num *
		xdev->a_lut_manager.segment_size) {
		dev_err(&xdev->pdev->dev,
			"%s addres not in BAR range: %llx\n", __func__, (u64)addr);
		return;
	}

	spin_lock(&xdev->alm_lock);

	plx_alm_del_entry(&xdev->a_lut_manager, xdev->pdev, segment_id,
		&start_segment, &segments_num);

	if (segments_num) {
		u32 permission_offset;
		int i;

		dev_dbg(&xdev->pdev->dev, "%s delete entry no %i translated %llx\n",
			__func__, segment_id, (u64)addr);

		for (i = start_segment; i < start_segment + segments_num; i++) {

			permission_offset = plx_get_a_lut_entry_offset(i) +
				PLX_A_LUT_PERMISSION_SUBARRAY_OFFSET;
			plx_mmio_write(&xdev->mmio, 0, xdev->a_lut_array_base + permission_offset);
		}
	}

	spin_unlock(&xdev->alm_lock);
}

/**
* plx_write_spad() - write to the scratchpad register
* @xdev: pointer to plx_device instance
* @idx: index to the scratchpad register, 0 based
* @val: the data value to put into the register
*
* This function allows writing of a 32bit value to the indexed scratchpad
* register.
*
* RETURNS: none.
*/
void plx_write_spad(struct plx_device *xdev, unsigned int idx, u32 val)
{
	dev_dbg(&xdev->pdev->dev, "Writing 0x%x to scratch pad index %d\n",
		val, idx);
	plx_mmio_write(&xdev->mmio, val, xdev->reg_base + PLX_SPAD0 + idx * 4);
}

/**
* plx_read_spad() - read from the scratchpad register
* @xdev: pointer to plx_device instance
* @idx: index to scratchpad register, 0 based
*
* This function allows reading of the 32bit scratchpad register.
*
* RETURNS: An appropriate -ERRNO error value on error, or zero for success.
*/
u32 plx_read_spad(struct plx_device *xdev, unsigned int idx)
{
	u32 val = plx_mmio_read(&xdev->mmio,
		xdev->reg_base + PLX_SPAD0 + idx * 4);

	dev_dbg(&xdev->pdev->dev,
		"Reading 0x%x from scratch pad index %d\n", val, idx);
	return val;
}

/**
* plx_enable_interrupts - Enable interrupts.
* @xdev: pointer to plx_device instance
*/
void plx_enable_interrupts(struct plx_device *xdev)
{
	u32 offset = xdev->reg_base + xdev->intr_reg_base
		+ PLX_DBIMC;
	plx_mmio_write(&xdev->mmio, 0xFFFF, offset);
}

/**
* plx_disable_interrupts - Disable interrupts.
* @xdev: pointer to plx_device instance
*/
void plx_disable_interrupts(struct plx_device *xdev)
{
	u32 offset = xdev->reg_base + xdev->intr_reg_base
		+ PLX_DBIMS;
	plx_mmio_write(&xdev->mmio, 0xFFFF, offset);
}

/**
* __plx_send_intr - Send interrupt to VCA.
* @xdev: pointer to plx_device instance
* @doorbell: doorbell number.
*/
void plx_send_intr(struct plx_device *xdev, int doorbell)
{
	u32 offset = xdev->reg_base + xdev->peer_intr_reg_base
		+ PLX_DBIS;

	plx_mmio_write(&xdev->mmio, DB_TO_MASK(doorbell), offset);
}

/**
* plx_ack_interrupt - Device specific interrupt handling.
* @xdev: pointer to plx_device instance
*
* Returns: bitmask of doorbell events triggered.
*/
u32 plx_ack_interrupt(struct plx_device *xdev)
{
	u32 offset = xdev->reg_base + xdev->intr_reg_base
		+ PLX_DBIC;
	u32 reg = plx_mmio_read(&xdev->mmio, offset);

	plx_mmio_write(&xdev->mmio, reg, offset);
	return reg;
}

/**
* plx_hw_intr_init() - Initialize h/w specific interrupt
* information.
* @xdev: pointer to plx_device instance
*/
void plx_intr_init(struct plx_device *xdev)
{
	xdev->intr_info = (struct plx_intr_info *)_plx_intr_init;
}

/**
* plx_dma_filter - DMA filter function
* @chan: The DMA channel to compare with
* @param: Data passed from DMA engine
*
* Returns: true if DMA device matches the PCIe device and false otherwise.
*/
bool plx_dma_filter(struct dma_chan *chan, void *param)
{
	struct device *dev = param;
	struct pci_dev *pdev = container_of(dev, struct pci_dev, dev);
	struct pci_dev *dma_dev =
		container_of(chan->device->dev, struct pci_dev, dev);
	u32 val;
	int rc;
	bool link_side;

	rc = pci_read_config_dword(pdev, PLX_PORT_ID, &val);
	if (rc) {
		dev_err(&pdev->dev, "can't read config dword: %d\n", rc);
		return false;
	}
	link_side = !!(val & (1 << 31));

	if (link_side)
	{
		/*
		* On the link side any DMA device is accepted
		*/
		dev_info(dev, "%s returning true\n", __func__);
		return true;
	}
	else
	{
		/* On host side only DMA engine assigned to the currently used
		* PCIe switch shall be used. Due to HW topology, it is at the
		* same level, as an upsteram port, two buses above NT port
		*/
		dev_dbg(dev, "%s Host side DMA filter looks for DMA at bus 0x%x\n",
			__func__,
			pdev->bus->parent->parent->number);
		if (pdev->bus->parent->parent->number == dma_dev->bus->number)
		{
			dev_info(dev, "%s Host side DMA filter accepts DMA at bus 0x%x\n",
				__func__,
				dma_dev->bus->number);
			return true;
		}
		else
		{
			dev_dbg(dev, "%s Host side DMA filter rejects DMA at bus 0x%x\n",
				__func__,
				dma_dev->bus->number);
			return false;
		}
	}
}

/**
* plx_program_bar23_at() - write to the BAR 2/3 Address Translation registers
* @xdev: pointer to plx_device instance
* @val: the data value to put into the registers
*
* This function splits 64 bit value to DWORDs and writes them to BAR 2 and 3
* address translation registers
*
* RETURNS: none.
*/
void plx_program_bar23_at(struct plx_device *xdev, u64 val)
{
	u32 lo, hi;
	lo = val;
	hi = (val >> 32);
	dev_dbg(&xdev->pdev->dev,
		"Writing 0x%x to BAR 2 Address Translation register\n",
		lo);
	plx_mmio_write(&xdev->mmio, lo,
		xdev->reg_base + PLX_BAR2_AT);
	dev_dbg(&xdev->pdev->dev,
		"Writing 0x%x to BAR 3 Address Translation register\n",
		hi);
	plx_mmio_write(&xdev->mmio, hi,
		xdev->reg_base + PLX_BAR3_AT);
}

/**
* plx_ioremap() - remaps memory from physical address to virtual address
* @xdev: pointer to plx_device instance
* @len: length of memory
*
* RETURNS: pointer to mapped memory.
*/
void __iomem * plx_ioremap(struct plx_device *xdev, dma_addr_t pa, size_t len)
{
	dma_addr_t pa_out = pa;
	dev_dbg(&xdev->pdev->dev, "%s physical address 0x%llx, len 0x%x\n",
		__func__, (u64)pa, (u32)len);

	if (xdev->a_lut) {
		if (plx_add_a_lut_entry(xdev, pa, len, &pa_out)) {
			dev_err(&xdev->pdev->dev,
				"cannot map pa in ALUT\n");
			return NULL;
		}
		dev_dbg(&xdev->pdev->dev,
			"%s Link side, ALUT translation done; remapping to 0x%llx\n",
			__func__,
			(u64)xdev->aper.va + pa_out);
	}
	else {
		dev_dbg(&xdev->pdev->dev,
			"%s Virtual side, no ALUT translation needed; direct remapping to 0x%llx\n",
			__func__,
			(u64)xdev->aper.va + pa);
	}

	return xdev->aper.va + pa_out;
}

/**
* plx_iounmap() - unmap from virtual memory
* @xdev: pointer to plx_device instance
* @va: virtual address to unmap
*
* RETURNS: none.
*/
void plx_iounmap(struct plx_device *xdev, void __iomem *va)
{
	dma_addr_t pa = (u64)(va - xdev->aper.va);
	dev_dbg(&xdev->pdev->dev, "%s virtual address 0x%llx and physical address 0x%llx\n", __func__, (u64)va, (u64)pa);

	if (xdev->a_lut) {
		plx_del_a_lut_entry(xdev, pa);
	}

}

/**
* plx_link_width() -returns the width of link(0 - default value, link down, but in case of power button value is undefined)
* @xdev: pointer to plx_device instance
* RETURNS: true if link is up, false otherwise
*/
u32 plx_link_width(struct plx_device *xdev)
{
	u32 data;
	data = plx_link_mmio_read(xdev, PLX_LINK_STATUS_AND_CONTROL_REGISTER);

	if ((data & PLX_LINK_GEN_BITMASK) >> PLX_LINK_GEN_OFFSET != PLX_LINK_GEN3_VALUE)
		return 0;
	return (data & PLX_LINK_WIDTH_BITMASK) >> PLX_LINK_WIDTH_OFFSET;
}

/**
* plx_get_state() - return state of the card
* @xdev: pointer to plx_device instance
* RETURNS: true if link is up, false otherwise
*/
u32 plx_get_state(struct plx_device *xdev)
{
	dev_err(&xdev->pdev->dev, "%s not implemented\n", __func__);
	return 0;
}

/**
* plx_get_cpu_num() - return number of cpu
* @xdev: pointer to plx_device instance
* RETURNS: number of CPUs available on card
*/
u32 plx_get_cpu_num(struct plx_device *xdev)
{
	u32 nums = 0;
	if (xdev->card_type & VCA_VV) {
		nums = PLX_VV_CPU_NUMS;
	}
	else if (xdev->card_type & VCA_MV) {
		nums = PLX_MV_CPU_NUMS;
	}
	else if (xdev->card_type & VCA_FPGA) {
		nums = PLX_FPGA_CPU_NUMS;
	}
	else if (xdev->card_type & VCA_VCAA) {
		nums = PLX_VCAA_CPU_NUMS;
	}
	else if (xdev->card_type & VCA_VCGA) {
		nums = PLX_VCAA_CPU_NUMS;
	}
	else {
		dev_err(&xdev->pdev->dev, "Unknown Card %d\n", xdev->card_id);
	}
	return nums;
}

u32 plx_get_memsize(struct plx_device *xdev)
{
	return xdev->lbp.i7_ddr_size_mb;
}

/**
* signal_bit - Set input bit to 0 for defined amount of time
* @xdev: pointer to plx_device instance
* @signal_completion: for thread to complete when driver unloads
* @bit: bit to set
* @offset: register offset
* @ms: amount of time in miliseconds to have bit set to 0
* @wait_start: completion to trigger moment when state start change
* @signal_release_ts: set jiffies when release signal
*/
static void signal_bit(struct plx_device *xdev,
	struct completion *signal_completion,
	u32 bit, u32 offset, u32 ms,
	struct completion *wait_start, u64 *signal_release_ts)
{
	bool signal_fail;
	u32 data;
	mutex_lock(&xdev->mmio_lock);
	data = plx_mmio_read(&xdev->mmio, offset);
	data &= ~bit;
	plx_mmio_write(&xdev->mmio, data, offset);
	mutex_unlock(&xdev->mmio_lock);

	if (wait_start)
		complete_all(wait_start);

	if (signal_completion)
		wait_for_completion_interruptible_timeout(signal_completion,
			msecs_to_jiffies(ms));
	else
		msleep(ms);

	mutex_lock(&xdev->mmio_lock);
	if (signal_release_ts)
		*signal_release_ts = get_jiffies_64();
	data = plx_mmio_read(&xdev->mmio, offset);
	signal_fail = (data & bit);
	data |= bit;
	plx_mmio_write(&xdev->mmio, data, offset);
	mutex_unlock(&xdev->mmio_lock);

	if (signal_fail)
		dev_err(&xdev->pdev->dev, "%s UNEXPECTED RESET SIGNAL bit %u offset "
			"%u time_ms %u\n", __func__, bit, offset, ms);
}
/**
* _set_bit - set input bit
* @xdev: pointer to plx_device instance
* @bit: bit to set
* @offset: register offset
*/
static void _set_bit(struct plx_device *xdev, u32 bit, u32 offset)
{
	u32 data;
	mutex_lock(&xdev->mmio_lock);
	data = plx_mmio_read(&xdev->mmio, offset);
	data |= bit;
	plx_mmio_write(&xdev->mmio, data, offset);
	mutex_unlock(&xdev->mmio_lock);
}

/**
* _clear - clear input bit
* @xdev: pointer to plx_device instance
* @bit: bit to reset
* @offset: register offset
*/
static void _clear_bit(struct plx_device *xdev, u32 bit, u32 offset)
{
	u32 data;
	mutex_lock(&xdev->mmio_lock);
	data = plx_mmio_read(&xdev->mmio, offset);
	data &= ~bit;
	plx_mmio_write(&xdev->mmio, data, offset);
	mutex_unlock(&xdev->mmio_lock);
}

/**
* plx_card_check_power_button_state - Read power button on VCA device.
* @xdev: pointer to plx_device instance
* @cpu_id: id of cpu to read status
* RETURNS: 0 if power button is released, positive number if power button
*     is pressed down, or time during padding between minimal time to change
*     button state, negative number if error.
*/
int plx_card_check_power_button_state(struct plx_device *xdev, int cpu_id)
{
	int ret = 0;
	if ((xdev->card_type & VCA_MV) || (xdev->card_type & VCA_FPGA)
		|| (xdev->card_type & VCA_VCAA) || (xdev->card_type & VCA_VCGA)) {
		u32 data;
		u32 bit = 0;

		if (cpu_id < 0 || cpu_id >= plx_get_cpu_num(xdev)) {
			dev_err(&xdev->pdev->dev, "Unknown CPU ID: card %d cpu %d\n",
				xdev->card_id, cpu_id);
			ret = -EINVAL;
			return ret;
		}

		bit = plx_power_button_bits[cpu_id];

		data = plx_mmio_read(&xdev->mmio, GPIO_REG);
		if (!(data & bit)) {
			ret = 1;
		}
		else {
			u64 time = get_jiffies_64();
			if (time_after_eq64(time, xdev->power_ts[cpu_id]) &&
				time_before64(time, xdev->power_ts[cpu_id]
					+ msecs_to_jiffies(POWER_GRACE_PERIOD_MS))) {
				ret = 2;
			}
		}
	}
	else if (!(xdev->card_type & VCA_VV)) {
		/* Ignore power button for VV cards, display error for others */
		dev_err(&xdev->pdev->dev, "Power status unsupported: card %d cpu %d\n",
			xdev->card_id, cpu_id);
		ret = -EINVAL;
	}

	return ret;
}

/*
* plx_card_press_power_button - Manages power button on VCA device.
* @xdev: pointer to plx_device instance
* @compl: for signal_bit to complete on driver unload
* @cpu_id: id of cpu to reset
* @hold: true to set power button hold, false to set power button toggle
* @wait_start: completion to trigger moment when button state start change
*/
void plx_card_press_power_button(struct plx_device *xdev,
	struct completion *compl, int cpu_id, bool hold,
	struct completion *wait_start)
{
	if ((xdev->card_type & VCA_MV) || (xdev->card_type & VCA_FPGA)
		|| (xdev->card_type & VCA_VCAA) || (xdev->card_type & VCA_VCGA)) {
		u32 bit = 0;
		if (cpu_id < 0 || cpu_id >= plx_get_cpu_num(xdev)) {
			if (wait_start)
				complete_all(wait_start);
			dev_err(&xdev->pdev->dev, "Unknown CPU ID: card %d cpu %d\n",
				xdev->card_id, cpu_id);
			return;
		}

		bit = plx_power_button_bits[cpu_id];

		dev_dbg(&xdev->pdev->dev, "Power OFF %s begin: card %d cpu %d\n",
			hold ? "hold" : "toggle", xdev->card_id, cpu_id);
		if (hold) {
			signal_bit(xdev, compl, bit, GPIO_REG, POWER_OFF_HOLD_TIME, wait_start, &xdev->power_ts[cpu_id]);
		}
		else {
			signal_bit(xdev, compl, bit, GPIO_REG, POWER_OFF_PULSE_TIME, wait_start, &xdev->power_ts[cpu_id]);
		}

		dev_dbg(&xdev->pdev->dev, "Power OFF %s end: card %d cpu %d\n",
			hold ? "hold" : "toggle", xdev->card_id, cpu_id);

	}
	else {
		if (wait_start)
			complete_all(wait_start);

		if (!(xdev->card_type & VCA_VV)) {
			/* Ignore power button for VV cards, display error for others */
			dev_err(&xdev->pdev->dev, "Power unsupported: card %d cpu %d\n", xdev->card_id, cpu_id);
		}
	}
}

/*
* plx_turn_rcv_mode - turn cpu bios recovery mode on/off
* @xdev - plx device instance
* @cpu_id - cpu id
*/
void plx_turn_rcv_mode(struct plx_device *xdev, u32 cpu_id, bool turn_on)
{
	if ((xdev->card_type & VCA_MV) || (xdev->card_type & VCA_FPGA) || (xdev->card_type & VCA_VCAA)) {
		if (turn_on)
			_clear_bit(xdev, plx_bios_rcv_bits[cpu_id], GPIO_REG);
		else
			_set_bit(xdev, plx_bios_rcv_bits[cpu_id], GPIO_REG);
	}
	else if (!(xdev->card_type & VCA_VCGA)) {
		if (turn_on)
			_clear_bit(xdev, plx_bios_rcv_bits_vcga[cpu_id], GPIO_REG);
		else
			_set_bit(xdev, plx_bios_rcv_bits_vcga[cpu_id], GPIO_REG);
	}
	else {
		dev_err(&xdev->pdev->dev, "Operation unsupported on card %d\n", xdev->card_id);
	}
}

/*
* plx_enable_bios_recovery - prepares cpu to boot gold bios
* @xdev - plx device instance
* @cpu_id - cpu id
*/
void plx_enable_bios_recovery_mode(struct plx_device *xdev, u32 cpu_id)
{
	if ((xdev->card_type & VCA_MV) || (xdev->card_type & VCA_FPGA)
		|| (xdev->card_type & VCA_VCAA) || (xdev->card_type & VCA_VCGA)) {
		plx_turn_rcv_mode(xdev, cpu_id, true);
	}
	else if (!(xdev->card_type & VCA_VV)) {
		dev_err(&xdev->pdev->dev, "Gold BIOS update unsupported: card %d\n", xdev->card_id);
	}
}

/*
* plx_disable_bios_recovery_mode- sets cpu to boot user bios
* @xdev - plx device instance
* @cpu_id - cpu id
*/
void plx_disable_bios_recovery_mode(struct plx_device *xdev, u32 cpu_id)
{
	if ((xdev->card_type & VCA_MV) || (xdev->card_type & VCA_FPGA)
		|| (xdev->card_type & VCA_VCAA) || (xdev->card_type & VCA_VCGA)) {
		plx_turn_rcv_mode(xdev, cpu_id, false);
	}
	else if (!(xdev->card_type & VCA_VV)) {
		dev_err(&xdev->pdev->dev, "Gold BIOS update unsupported: card %d\n", xdev->card_id);
	}
}

/**
* plx_identify_cpu_id - get the id of cpu on VCA card.
* @xdev: pointer to plx_device instance
* RETURNS: -1 on error, cpu id otherwise
*/
int plx_identify_cpu_id(struct pci_dev *pdev)
{
	if (pdev->vendor == PCI_VENDOR_ID_INTEL
#ifdef RDK_SUPPORT
		|| pdev->vendor == PLX_PCI_VENDOR_ID_PLX
#endif
		) {
		switch (pdev->device) {
		case INTEL_VCA_PCI_NODE0_ID:
#ifdef RDK_SUPPORT
		case PLX_PCI_DEVICE_87B0:
#endif
			return 0;
		case INTEL_VCA_PCI_NODE1_ID:
#ifdef RDK_SUPPORT
		case PLX_PCI_DEVICE_87B1:
#endif
			return 1;
		case INTEL_VCA_PCI_NODE2_ID:
			return 2;
		};
	}

	return -1;
}

static enum plx_eep_retval eeprom_wait_for_cmd_complete(struct plx_device *xdev)
{
	struct plx_eep_status_register status;
	unsigned tries_left = PLX_EEP_WAIT_TRIES;

	do {
		status.value = plx_mmio_read(&xdev->mmio, PLX_EEP_STATUS_CONTROL);
		if (status.eep_cmd_status == 0)
			return PLX_EEP_STATUS_OK;

		usleep_range(PLX_EEP_WAIT_US, 2 * PLX_EEP_WAIT_US);
		tries_left--;
	} while (tries_left);

	return PLX_EEP_TIMEOUT;
}

static enum plx_eep_retval eeprom_send_cmd(struct plx_device *xdev, u32 cmd, u16 offset)
{
	enum plx_eep_retval ret;

	plx_mmio_write(&xdev->mmio, cmd, offset);

	ret = eeprom_wait_for_cmd_complete(xdev);
	if (ret != PLX_EEP_STATUS_OK) {
		dev_err(&xdev->pdev->dev,
			"%s: error when waiting for cmd to complete!\n",
			__func__);
		return ret;
	}
	return PLX_EEP_STATUS_OK;
}

static enum plx_eep_retval eeprom_wait_for_access_ready(struct plx_device *xdev)
{
	enum plx_eep_retval ret;
	struct plx_eep_status_register status;
	unsigned tries_left = PLX_EEP_WAIT_TRIES;

	status.value = plx_mmio_read(&xdev->mmio, PLX_EEP_STATUS_CONTROL);

	status.eep_cmd = PLX_EEP_CMD_READ_STATUS;
	status.eep_ready = 0;
	status.eep_write_status = 0;

	do {
		ret = eeprom_send_cmd(xdev, status.value, PLX_EEP_STATUS_CONTROL);
		if (ret != PLX_EEP_STATUS_OK) {
			dev_err(&xdev->pdev->dev,
				"%s: failed sending eeprom register cmd!\n",
				__func__);
			return ret;
		}

		status.value = plx_mmio_read(&xdev->mmio, PLX_EEP_STATUS_CONTROL);

		// check EEPROM read & write status
		if (status.eep_ready == 0 && status.eep_write_status == 0)
			return PLX_EEP_STATUS_OK;

		usleep_range(PLX_EEP_WAIT_US, 2 * PLX_EEP_WAIT_US);
		tries_left--;
	} while (tries_left);

	return PLX_EEP_TIMEOUT;
}

static enum plx_eep_retval eeprom_read32(struct plx_device *xdev, u32 offset, u32 *value_32)
{
	enum plx_eep_retval ret;
	struct plx_eep_status_register status;
	*value_32 = 0;

	ret = eeprom_wait_for_access_ready(xdev);
	if (ret != PLX_EEP_STATUS_OK) {
		dev_err(&xdev->pdev->dev,
			"%s: error when waiting for eeprom access ready...\n",
			__func__);
		return ret;
	}

	status.value = plx_mmio_read(&xdev->mmio, PLX_EEP_STATUS_CONTROL);

	offset = (offset / sizeof(u32));

	status.eep_blk_addr = offset;
	status.eep_cmd = PLX_EEP_CMD_READ;
	status.eep_blk_addr_upper_bit = 0;

	ret = eeprom_send_cmd(xdev, status.value, PLX_EEP_STATUS_CONTROL);
	if (ret != PLX_EEP_STATUS_OK) {
		dev_err(&xdev->pdev->dev,
			"%s: failed sending eeprom register cmd!\n",
			__func__);
		return ret;
	}

	*value_32 = plx_mmio_read(&xdev->mmio, PLX_EEP_BUFFER);

	return PLX_EEP_STATUS_OK;
}

static enum plx_eep_retval eeprom_read16(struct plx_device *xdev, u32 offset, u16 *value_16)
{
	enum plx_eep_retval ret;
	u32 value_32;

	*value_16 = 0;

	ret = eeprom_read32(xdev, offset & ~0x3, &value_32);
	if (ret != PLX_EEP_STATUS_OK) {
		dev_err(&xdev->pdev->dev,
			"%s: failed to read value_32 on offset %08x...\n",
			__func__, offset);
		return ret;
	}

	if (offset & 0x3)
		*value_16 = (u16)(value_32 >> 16);
	else
		*value_16 = (u16)value_32;

	return PLX_EEP_STATUS_OK;
}

static enum plx_eep_retval eeprom_write32(struct plx_device *xdev, u16 offset, u32 value_32)
{
	enum plx_eep_retval ret;
	struct plx_eep_status_register status;

	ret = eeprom_wait_for_access_ready(xdev);
	if (ret != PLX_EEP_STATUS_OK) {
		dev_err(&xdev->pdev->dev,
			"%s: error when waiting for eeprom access ready...\n",
			__func__);
		return ret;
	}

	status.value = plx_mmio_read(&xdev->mmio, PLX_EEP_STATUS_CONTROL);

	offset = (offset / sizeof(u32));

	status.eep_blk_addr = 0;
	status.eep_cmd = PLX_EEP_CMD_WRITE_ENABLE;
	status.eep_blk_addr_upper_bit = 0;

	ret = eeprom_send_cmd(xdev, status.value, PLX_EEP_STATUS_CONTROL);
	if (ret != PLX_EEP_STATUS_OK) {
		dev_err(&xdev->pdev->dev,
			"%s: failed sending eeprom register cmd!\n",
			__func__);
		return ret;
	}

	plx_mmio_write(&xdev->mmio, value_32, PLX_EEP_BUFFER);

	status.eep_blk_addr = offset;
	status.eep_cmd = PLX_EEP_CMD_WRITE;
	status.eep_blk_addr_upper_bit = 0;

	ret = eeprom_send_cmd(xdev, status.value, PLX_EEP_STATUS_CONTROL);
	if (ret != PLX_EEP_STATUS_OK) {
		dev_err(&xdev->pdev->dev,
			"%s: failed sending eeprom register cmd!\n",
			__func__);
		return ret;
	}

	return PLX_EEP_STATUS_OK;
}

static enum plx_eep_retval eeprom_write16(struct plx_device *xdev, u16 offset, u16 value_16)
{
	enum plx_eep_retval ret;
	u32 value_32;

	ret = eeprom_read32(xdev, offset & ~0x3, &value_32);
	if (ret != PLX_EEP_STATUS_OK) {
		dev_err(&xdev->pdev->dev,
			"%s: failed to read value32 on offset %08x...\n",
			__func__, offset);
		return ret;
	}

	if (offset & 0x3)
		value_32 = ((u32)value_16 << 16) | (value_32 & 0xFFFF);
	else
		value_32 = ((u32)value_16) | (value_32 & 0xFFFF0000);

	ret = eeprom_write32(xdev, offset & ~0x3, value_32);
	if (ret != PLX_EEP_STATUS_OK) {
		dev_err(&xdev->pdev->dev,
			"%s: failed to write value_32 on offset %08x...\n",
			__func__, offset);
		return ret;
	}

	return PLX_EEP_STATUS_OK;
}

static enum plx_eep_retval eeprom_check_crc(struct plx_device *xdev, char *eeprom_data,
	size_t eeprom_size)
{
	enum plx_eep_retval ret;
	u16 i;
	u32 next_crc_value;
	u32 crc_value;
	u32 xor_value;
	u32 crc_offset;
	u32 crc_calculated = ~0U;
	u32 crc_end_offset = eeprom_size - PLX_EEP_CRC_LENGTH_BYTE;

	for (crc_offset = PLX_EEP_START_CRC_OFFSET; crc_offset < crc_end_offset; crc_offset += sizeof(u32))
	{
		if (crc_end_offset - crc_offset == 2)
			next_crc_value = *(u16*)(eeprom_data + crc_offset);
		else
			next_crc_value = *(u32*)(eeprom_data + crc_offset);

		for (i = 0; i < 32; ++i)
		{
			xor_value = ((crc_calculated ^ (next_crc_value << i)) & (1 << 31));

			if (xor_value)
				xor_value = PLX_EEP_CONST_CRC_XOR_VALUE;
			else
				xor_value = 0;

			crc_calculated = (crc_calculated << 1) ^ xor_value;
		}
	}

	crc_value = *(u32*)(eeprom_data + crc_end_offset);

	if (crc_calculated != crc_value)
		ret = PLX_EEP_INTERNAL_ERROR;
	else
		ret = PLX_EEP_STATUS_OK;

	return ret;
}

static enum plx_eep_retval eeprom_validate(struct plx_device *xdev, char *eeprom_data,
	size_t eeprom_size)
{
	struct eeprom_header {
		unsigned char validation_signature;
		unsigned char flags;
		unsigned short configuration_size;
	};
	struct eeprom_header *header = (struct eeprom_header *)eeprom_data;
	enum plx_eep_retval ret = PLX_EEP_STATUS_OK;

	if (eeprom_size <= PLX_EEP_HEADER_LENGTH_BYTE + PLX_EEP_CRC_LENGTH_BYTE) {
		dev_err(&xdev->pdev->dev, "Eeprom file is too short!\n");
		return PLX_EEP_INTERNAL_ERROR;
	}

	dev_dbg(&xdev->pdev->dev, "Eeprom config header: signature:%02x flags:%02x size:%04x\n",
		(u32)header->validation_signature,
		(u32)header->flags,
		(u32)header->configuration_size);

	if (header->configuration_size % PLX_EEP_CONFIGURATION_ALIGNMENT_BYTE) {
		dev_err(&xdev->pdev->dev, "Invalid eeprom configuration size!\n");
		return PLX_EEP_INTERNAL_ERROR;
	}

	if ((eeprom_size - PLX_EEP_HEADER_LENGTH_BYTE - PLX_EEP_CRC_LENGTH_BYTE) != header->configuration_size) {
		dev_err(&xdev->pdev->dev, "Size mismatch!\n");
		return PLX_EEP_INTERNAL_ERROR;
	}

	if (header->validation_signature != PLX_EEP_VALIDATION_HEADER) {
		dev_err(&xdev->pdev->dev, "Invalid validation signature!\n");
		return PLX_EEP_INTERNAL_ERROR;
	}

	ret = eeprom_check_crc(xdev, eeprom_data, eeprom_size);
	if (ret != PLX_EEP_STATUS_OK) {
		dev_err(&xdev->pdev->dev, "Calculate CRC is different that provided in eeprom file!\n");
		return ret;
	}

	return ret;
}

/*
* plx_update_eeprom - write user provided configuration to EEPROM
*
* @xdev - pointer to plx device
* @eeprom_data  - eeprom content in following layout:
*	4B - header:
*		1B - validation_signature
*		1B - flags
*		2B - configuration_size
*	(2B, 4B) x configuration_size - (register address, register value) pairs
*	4B - CRC
* @eeprom_size - configuration_size passed by user
*
* RETURNS: PLX_EEP_STATUS_OK on success,
*	   PLX_EEP_INTERNAL_ERROR or PLX_EEP_TIMEOUT on failure
*/
enum plx_eep_retval plx_update_eeprom(struct plx_device *xdev, char *eeprom_data,
	size_t eeprom_size)
{
	u16 offset;
	u16 verify_value_16;
	u32 verify_value_32;
	u32 value_32;
	enum plx_eep_retval ret;
	u32 eep_3rd_addr_byte_reg;

	ret = eeprom_validate(xdev, eeprom_data, eeprom_size);
	if (ret != PLX_EEP_STATUS_OK)
		return ret;

	mutex_lock(&xdev->mmio_lock);

	eep_3rd_addr_byte_reg = plx_mmio_read(&xdev->mmio, PLX_EEP_ADDRESS_BYTE);

	if (eep_3rd_addr_byte_reg & 0x3)
		plx_mmio_write(&xdev->mmio,
			eep_3rd_addr_byte_reg & (PLX_EEP_3RD_ADDRES_BYTE_RSVD_MASK | PLX_EEP_EXPANSION_ROM_BASE_ADDR_MASK),
			PLX_EEP_ADDRESS_BYTE);

	for (offset = 0; offset < eeprom_size; offset += sizeof(u32))
	{
		// if eeprom data is not dword aligned
		if (eeprom_size - offset == 2) {
			value_32 = *(u16*)(eeprom_data + offset);

			ret = eeprom_write16(xdev, offset, value_32);
			if (ret != PLX_EEP_STATUS_OK) {
				dev_err(&xdev->pdev->dev,
					"%s: failed to write value_32 %08x on offset %08x!\n",
					__func__, value_32, offset);
				goto unlock;
			}

			ret = eeprom_read16(xdev, offset, &verify_value_16);
			if (ret != PLX_EEP_STATUS_OK) {
				dev_err(&xdev->pdev->dev,
					"%s: failed to read value_16 from offset %08x !\n",
					__func__, offset);
				goto unlock;
			}

			if ((u16)value_32 != verify_value_16) {
				dev_err(&xdev->pdev->dev, "value_16 into eeprom (%08x) is "
					"different with value_16 in file (%08x) !\n",
					verify_value_16, value_32);
				ret = PLX_EEP_INTERNAL_ERROR;
				goto unlock;
			}
			break;
		}

		value_32 = *(u32*)(eeprom_data + offset);

		ret = eeprom_write32(xdev, offset, value_32);
		if (ret != PLX_EEP_STATUS_OK) {
			dev_err(&xdev->pdev->dev,
				"%s: failed to write value_32 %08x on offset %08x!\n",
				__func__, value_32, offset);
			goto unlock;
		}

		ret = eeprom_read32(xdev, offset, &verify_value_32);
		if (ret != PLX_EEP_STATUS_OK) {
			dev_err(&xdev->pdev->dev,
				"%s: failed to read value_32 %08x on offset %08x!\n",
				__func__, verify_value_32, offset);
			goto unlock;
		}

		if (value_32 != verify_value_32) {
			dev_err(&xdev->pdev->dev, "value_32 into eeprom (%08x) is "
				"different with value_32 in file (%08x) !\n", verify_value_32, value_32);
			ret = PLX_EEP_INTERNAL_ERROR;
			goto unlock;
		}
	}
unlock:
	mutex_unlock(&xdev->mmio_lock);
	return ret;
}

/**
* plx_set_dp_addr - Write boot params address to spad
* @xdev: pointer to plx_device instance
* @dp_addr: remote address to copy
*/
void plx_set_dp_addr(struct plx_device *xdev, u64 dp_addr)
{
	dev_dbg(&xdev->pdev->dev, "%s Write dp addr 0x%llx \n", __func__, dp_addr);
	plx_write_spad(xdev, PLX_DPLO_SPAD, dp_addr);
	plx_write_spad(xdev, PLX_DPHI_SPAD, dp_addr >> 32);
}

/**
* plx_set_dp_addr - Read remote address to boot params from spad
* @xdev: pointer to plx_device instance
*
* RETURNS: Remote address to boot params rdp.
*
*/
u64 plx_get_dp_addr(struct plx_device *xdev)
{
	u64 lo, hi, dp_addr;
	lo = plx_read_spad(xdev, PLX_DPLO_SPAD);
	hi = plx_read_spad(xdev, PLX_DPHI_SPAD);
	dp_addr = lo | (hi << 32);
	dev_err(&xdev->pdev->dev, "%s Read dp_addr 0x%llx \n", __func__, dp_addr);
	return dp_addr;
}

/* Initialize the device page */
static int plx_dp_init(struct plx_device *xdev)
{
	xdev->dp = dma_zalloc_coherent(&xdev->pdev->dev, VCA_DP_SIZE,
		&xdev->dp_dma_addr, GFP_KERNEL);
	if (!xdev->dp) {
		dev_err(&xdev->pdev->dev, "%s %d err %d\n",
			__func__, __LINE__, -ENOMEM);
		return -ENOMEM;
	}

	return 0;
}

/* Uninitialize the device page */
static void plx_dp_uninit(struct plx_device *xdev)
{
	dev_info(&xdev->pdev->dev, "%s entered\n", __func__);
	dma_free_coherent(&xdev->pdev->dev, VCA_DP_SIZE, xdev->dp,
		xdev->dp_dma_addr);
	plx_set_dp_addr(xdev, 0);

}

/* Notify remote side about initialized DP*/
static void plx_dp_notify(struct plx_device *xdev)
{
	u32 notify;
	dev_info(&xdev->pdev->dev, "%s writing dp_dma_addr:%llx\n",
		__func__, xdev->dp_dma_addr);
	plx_set_dp_addr(xdev, xdev->dp_dma_addr);

	if (!(xdev->card_type & VCA_PRODUCTION)) {
		notify = plx_read_spad(xdev, PLX_HSDB_SPAD);
		if ((notify & PLX_HSDB_MASK) >> PLX_HSDB_SHIFT == PLX_HSDB_CMD) {
			dev_info(&xdev->pdev->dev,
				"Send doorbell %d\n", notify & ~PLX_HSDB_MASK);
			plx_send_intr(xdev, notify & ~PLX_HSDB_MASK);
		}
		xdev->hs_done = true;
	}
}

static int plx_rdp_init(struct plx_device *xdev)
{
	struct vca_bootparam __iomem *bootparam;
	u64 dp_dma_addr;
	u32 magic = 0;
	u32 version = 0;
	int err = 0;

	dp_dma_addr = plx_get_dp_addr(xdev);

	dev_info(&xdev->pdev->dev, "%s reading dp_dma_addr:0x%llx\n",
		__func__, dp_dma_addr);

	if ((dp_dma_addr == 0x0L) || (dp_dma_addr == 0xffffffffffffffffL)) {
		err = -ENODEV;
		goto skip_rdp;
	}

	xdev->rdp = NULL;
	xdev->rdp = plx_ioremap(xdev, dp_dma_addr, VCA_DP_SIZE);
	if (!xdev->rdp) {
		dev_err(&xdev->pdev->dev,
			"cannot map dp_dma_addr in ALUT\n");
		err = -ENOMEM;
		goto skip_rdp;
	}

	dp_dma_addr = xdev->rdp - xdev->aper.va;

	dev_info(&xdev->pdev->dev, "dp_dma_addr mapped as 0x%llx offset in BAR\n",
		dp_dma_addr);

	dev_info(&xdev->pdev->dev, "bar size is %llx, rdp address is %llx\n",
		(u64)xdev->aper.len, dp_dma_addr);

	bootparam = xdev->rdp;
	magic = ioread32(&bootparam->magic);

	if (VCA_MAGIC != magic) {
		dev_err(&xdev->pdev->dev,
			"bootparam magic mismatch 0x%x\n", magic);
		err = -EINVAL;
		goto skip_rdp;
	}
	else {
		dev_info(&xdev->pdev->dev, "%s magic is OK: %x", __func__, magic);
	}

	version = ioread32(&bootparam->version_host);
	iowrite32(VCA_PROTOCOL_VERSION, &bootparam->version_card);

	if (VCA_PROTOCOL_VERSION != version) {
		dev_err(&xdev->pdev->dev, "%s Protocol version mismatch. "
			"Host version is 0x%x, but expected 0x%x\n",
			__func__, version, VCA_PROTOCOL_VERSION);
		err = -EINVAL;
	}
	else {
		dev_err(&xdev->pdev->dev, "%s Correct protocol version 0x%x\n",
			__func__, VCA_PROTOCOL_VERSION);
	}

skip_rdp:
	if (err) {
		xdev->hs_done = false;
		plx_write_spad(xdev, PLX_LBP_SPAD_i7_READY, PLX_LBP_i7_GENERAL_ERROR);
		if (xdev->rdp) {
			plx_iounmap(xdev, xdev->rdp);
			xdev->rdp = NULL;
			err = -EIO;
		}
	}
	else {
		xdev->hs_done = true;
		plx_write_spad(xdev, PLX_LBP_SPAD_i7_READY, PLX_LBP_i7_DRV_PROBE_DONE);
	}
	return err;
}

/**
* plx_device_init - Allocates and initializes the VCA device structure
*
* @xdev: pointer to plx_device instance
* @pdev: The pci device structure
*
* returns none.
*/
static void
plx_device_init(struct plx_device *xdev, struct pci_dev *pdev)
{
	int i;
	xdev->pdev = pdev;
	xdev->irq_info.next_avail_src = 0;
	xdev->dma_ch = NULL;
	mutex_init(&xdev->mmio_lock);
	mutex_init(&xdev->reset_lock);
	mutex_lock(&xdev->reset_lock);
	xdev->reset_ts = INITIAL_JIFFIES - msecs_to_jiffies(RESET_GRACE_PERIOD_MS);
	for (i = 0; i < MAX_VCA_CARD_CPUS; ++i)
		xdev->power_ts[i] = INITIAL_JIFFIES - msecs_to_jiffies(POWER_GRACE_PERIOD_MS);
	mutex_unlock(&xdev->reset_lock);

}

/**
* plx_free_dma_chan - release DMA channel
* @xdev: pointer to plx_device instance
*
* returns none
*/
static void plx_free_dma_chan(struct plx_device *xdev)
{
	if (xdev->dma_ch) {
		sysfs_remove_link(&xdev->pdev->dev.kobj, VCA_DMA_LINK_NAME);
		dma_release_channel(xdev->dma_ch);
		xdev->dma_ch = NULL;
	}
}

/* helper function to check if pointer is NULL or error. In such case pointer is set to NULL,
* error is logged and error code is returned. If pointer looks good nothing happens and function
* returns with 0 */
static inline int _validate_ptr(struct plx_device* xdev, void** ptr, const char* name)
{
	int rc = 0;
	if (IS_ERR_OR_NULL(*ptr)) {
		if (!(*ptr)) {
			rc = -ENODEV;
			dev_err(&xdev->pdev->dev, "failed to register %s device\n", name);
		}
		else {
			rc = PTR_ERR(*ptr);
			dev_err(&xdev->pdev->dev, "failed to register %s device, rc=%d\n", name, rc);
		}
		*ptr = NULL;
	}
	return rc;
}

static enum vca_card_type plx_card_get_type(struct pci_dev *pdev)
{
	switch (pdev->subsystem_device) {
	case SUBSYSTEM_ID_VV_POC:
		return VCA_POC;
	case SUBSYSTEM_ID_VV_FAB1:
		return VCA_VV_FAB1;
	case SUBSYSTEM_ID_VV_FAB2:
		return VCA_VV_FAB2;
	case SUBSYSTEM_ID_MV_FAB1:
		return VCA_MV_FAB1;
	case SUBSYSTEM_ID_VCAA_FAB1:
		return VCA_VCAA_FAB1;
	case SUBSYSTEM_ID_VCGA_FAB1:
		return VCA_VCGA_FAB1;
	case SUBSYSTEM_ID_FPGA_FAB1:
		return VCA_FPGA_FAB1;
	}
	dev_err(&pdev->dev, "Unknown card type! subsystemID 0x%x\n",
		pdev->subsystem_device);
	return VCA_UNKNOWN;
}

/**
* plx_identify_self - Find on what PCI-e card this device is and its type
* @pdev: PCI device structure
* return 0 on success, < 0 on failure.
*/
static int plx_identify_self(struct plx_device *xdev)
{
	/* Identified Card ID not on the PCI topology,
	* but check PCI list device and detect numbers
	* of previous occurrences NODE0 related with actual node.
	* Devices on the PCI list have to be in that same ordering on host and VM.
	* */
	struct pci_dev * pdev = xdev->pdev;
	struct pci_dev * found_dev = NULL;
	int card_id = -1;

	while ((found_dev = pci_get_device(
#ifdef RDK_SUPPORT
		PCI_ANY_ID,
#else
		PCI_VENDOR_ID_INTEL,
#endif
		PCI_ANY_ID, found_dev)) != NULL) {

		/* Ignore not related devices. */
		if (plx_identify_cpu_id(found_dev) < 0) {
			continue;
		}

		dev_dbg(&pdev->dev, "Found vendor %u device %u subsystem_vendor %u "
			"subsystem_device %u Card ID: %i %s\n", found_dev->vendor,
			found_dev->device, found_dev->subsystem_vendor,
			found_dev->subsystem_device, plx_identify_cpu_id(found_dev),
			(xdev->pdev == found_dev) ? " This device" : "");

		/* to identify CPU0, new Card */
		if (plx_identify_cpu_id(found_dev) == 0)
			card_id++;

		/* Check that this device is related with instance of drivers. */
		if (xdev->pdev == found_dev)
			break;
	}

	if (found_dev == NULL || card_id < 0)
		return -ENOENT;

	xdev->card_id = card_id;

	dev_info(&pdev->dev, "Identify CARD_ID: %i, CPU_ID %i\n", xdev->card_id,
		plx_identify_cpu_id(xdev->pdev));

	return 0;
}


/**
* plx_device_create - Creates plx device
* @xdev: Pointer to created device
* @pdev: PCI device structure
* returns 0 on success, < 0 on failure.
*/
static int plx_device_create(struct plx_device **xdevp, struct pci_dev *pdev)
{
	int rc = 0;
	struct plx_device *xdev;
	xdev = kzalloc(sizeof(*xdev), GFP_KERNEL);
	if (!xdev) {
		rc = -ENOMEM;
		dev_err(&pdev->dev, "xdev kmalloc failed rc %d\n", rc);
		goto finish;
	}

	xdev->id = ida_simple_get(&g_plx_ida, 0, VCA_MAX_NUM_CPUS, GFP_KERNEL);
	if (xdev->id < 0) {
		rc = xdev->id;
		dev_err(&pdev->dev, "ida_simple_get failed rc %d\n", rc);
		goto ida_fail;
	}

	*xdevp = xdev;
	goto finish;

ida_fail:
	kfree(xdev);
finish:
	return rc;
}

/**
* plx_device_destroy - Destroys plx device
* @xdev: Pointer to plx device to destroy
*/
static void plx_device_destroy(struct plx_device *xdev)
{
	ida_simple_remove(&g_plx_ida, xdev->id);
	kfree(xdev);
}

/**
* plx_pci_device_init - Init pci device for plx device
* @pdev: PCI device structure
* returns 0 on success, < 0 on failure.
*/
static int plx_pci_device_init(struct pci_dev *pdev)
{
	int rc = pci_enable_device(pdev);
	if (rc) {
		dev_err(&pdev->dev, "failed to enable pci device.\n");
		goto finish;
	}

	pci_set_master(pdev);

	rc = pci_request_regions(pdev, plx_driver_name);
	if (rc) {
		dev_err(&pdev->dev, "failed to get pci regions.\n");
		goto disable_device;
	}

	rc = pci_set_dma_mask(pdev, DMA_BIT_MASK(64));
	if (rc) {
		dev_err(&pdev->dev, "Cannot set DMA mask\n");
		goto release_regions;
	}
	goto finish;

release_regions:
	pci_release_regions(pdev);
disable_device:
	pci_disable_device(pdev);
finish:
	return rc;
}

/**
* plx_pci_device_deinit - Deinitialize pci device used by plx device
* @pdev: PCI device structure
*/
static void plx_pci_device_deinit(struct pci_dev *pdev)
{
	pci_release_regions(pdev);
	pci_disable_device(pdev);
}

/**
* plx_unmap_resources - Unmaps resources used by device
* @xdev: plx device structure
* @pdev: PCI device structure
*/
static void plx_unmap_resources(struct plx_device *xdev)
{
	iounmap(xdev->aper.va);
	iounmap(xdev->mmio.va);
}

/**
* plx_dealloc_blockio_dev_page - deallocate memory used for blockio device injection
* @xdev: plx device structure
*/
static void plx_dealloc_blockio_dev_page(struct plx_device *xdev)
{
	if (xdev->blockio.dp_va) {
		dma_free_coherent(&xdev->pdev->dev,
			BLOKIO_DEVPAGE_SIZE,
			xdev->blockio.dp_va,
			xdev->blockio.dp_da);
		xdev->blockio.dp_va = NULL;
		xdev->blockio.dp_da = 0;
	}
}

/**
* plx_probe - Device Initialization Routine
*
* @pdev: PCI device structure
* @ent: entry in plx_pci_tbl
*
* returns 0 on success, < 0 on failure.
*/
static int plx_probe(struct pci_dev *pdev,
	const struct pci_device_id *ent)
{
	int rc;
	struct plx_device *xdev;
	enum vca_card_type card_type = VCA_UNKNOWN;

	dev_info(&pdev->dev,
		"buildinfo: build no " BUILD_NUMBER ", built on " BUILD_ONDATE ".\n");
	card_type = plx_card_get_type(pdev);
	if (card_type == VCA_UNKNOWN) {
		rc = -ENXIO;
		dev_err(&pdev->dev, "Unknown card type! subsystemID 0x%x\n",
			pdev->subsystem_device);
		goto plx_create_device_fail;
	}
	else if (card_type & VCA_VV) {
		dev_info(&pdev->dev, "Detected device 'ValleyVista' subsystemID 0x%x\n",
			pdev->subsystem_device);
	}
	else if (card_type & VCA_MV) {
		dev_info(&pdev->dev, "Detected device 'MonteVista' subsystemID 0x%x\n",
			pdev->subsystem_device);
	}
	else if (card_type & VCA_FPGA) {
		dev_info(&pdev->dev, "Detected device 'FPGA' subsystemID 0x%x\n",
			pdev->subsystem_device);
	}
	else if (card_type & VCA_VCAA) {
		dev_info(&pdev->dev, "Detected device 'VCAA' subsystemID 0x%x\n",
			pdev->subsystem_device);
	}
	else if (card_type & VCA_VCGA) {
		dev_info(&pdev->dev, "Detected device 'VCGA' subsystemID 0x%x\n",
			pdev->subsystem_device);
	}

	rc = plx_device_create(&xdev, pdev);
	if (rc) {
		dev_err(&pdev->dev, "plx_device_create failed %d\n", rc);
		goto plx_create_device_fail;
	}

	plx_device_init(xdev, pdev);

	xdev->card_type = card_type;

	rc = plx_pci_device_init(pdev);
	if (rc) {
		dev_err(&pdev->dev, "plx_pci_device_init failed %d\n", rc);
		goto destroy_plx_device;
	}

	xdev->mmio.pa = pci_resource_start(pdev, PLX_MMIO_BAR);
	xdev->mmio.len = pci_resource_len(pdev, PLX_MMIO_BAR);
	xdev->mmio.va = pci_ioremap_bar(pdev, PLX_MMIO_BAR);

	xdev->aper.pa = pci_resource_start(pdev, PLX_APER_BAR);
	xdev->aper.len = pci_resource_len(pdev, PLX_APER_BAR);
	xdev->aper.va = ioremap_wc(xdev->aper.pa, xdev->aper.len);

	rc = plx_hw_init(xdev, pdev);
	if (rc) {
		dev_err(&pdev->dev, "plx_hw_init failed %d\n", rc);
		goto unmap_resources;
	}

	if (!xdev->link_side) {
		rc = plx_identify_self(xdev);
		if (rc) {
			dev_err(&pdev->dev,
				"Could not identify card for pci_device with "
				"vendor %x, device_id %x !\n",
				(unsigned int)PCI_VENDOR_ID_INTEL,
				(unsigned int)INTEL_VCA_PCI_NODE0_ID);
			goto unmap_resources;
		}

		xdev->mmio_link_offset = plx_identify_cpu_id(xdev->pdev) == 1
			? 0x3d000 : 0x3f000;
	}

	plx_intr_init(xdev);
	pci_set_drvdata(pdev, xdev);

	if (!xdev->link_side) {
		rc = plx_dp_init(xdev);
		if (rc) {
			dev_err(&pdev->dev, "plx_dp_init failed rc %d\n", rc);
			goto free_interrupts;
		}
		plx_dp_notify(xdev);
	}
	else {
		rc = plx_rdp_init(xdev);
		if (rc) {
			dev_err(&pdev->dev, "plx_rdp_init failed rc %d\n", rc);
			goto free_interrupts;
		}
	}

	dev_info(&pdev->dev, "link side %d\n", xdev->link_side);

	rc = 0; /* Ignore warnings, when not cleanup driver. */
	goto exit;

free_interrupts:
unmap_resources:
	if ((xdev->link_side) && (rc != -EPROBE_DEFER))
		plx_write_spad(xdev, PLX_LBP_SPAD_i7_READY, PLX_LBP_i7_DRV_PROBE_ERROR);
	plx_unmap_resources(xdev);
destroy_plx_device:
	plx_device_destroy(xdev);
plx_create_device_fail:
	dev_err(&pdev->dev, "Probe failed rc %d\n", rc);
exit:
	return rc;
}

/**
* plx_remove - Device Removal Routine
* plx_remove is called by the PCI subsystem to alert the driver
* that it should release a PCI device.
*
* @pdev: PCI device structure
*/
static void plx_remove(struct pci_dev *pdev)
{
	struct plx_device *xdev = pci_get_drvdata(pdev);

	if (!xdev)
		return;
	if (xdev->link_side)
		plx_dealloc_blockio_dev_page(xdev);
	plx_hw_deinit(xdev);
	plx_mmio_write(&xdev->mmio, 0, xdev->reg_base + PLX_A_LUT_CONTROL);
	plx_free_dma_chan(xdev);
	if (!xdev->link_side)
		plx_dp_uninit(xdev);
	plx_unmap_resources(xdev);
	plx_pci_device_deinit(pdev);
	plx_device_destroy(xdev);
}

static void plx_shutdown(struct pci_dev *pdev)
{
	plx_remove(pdev);
}

static struct pci_driver plx_driver = {
	.name = plx_driver_name,
	.id_table = plx_pci_tbl,
	.probe = plx_probe,
	.remove = plx_remove,
	.shutdown = plx_shutdown
};

static void __exit plx_exit(void)
{
	pci_unregister_driver(&plx_driver);
	ida_destroy(&g_plx_ida);
	plx_exit_procfs();
}

/* Not use in release version, from performance reasons. */
//#define DEBUG_ALM_CHECK

#ifdef DEBUG_ALM_CHECK
#define PLX_ALM_CHECK(alm, pdev) plx_alm_check(alm, pdev)
#else /* DEBUG_ALM_VALIDATE */
#define PLX_ALM_CHECK(alm, pdev)
#endif /* DEBUG_ALM_VALIDATE */

/*
* plx_alm_entries_dmesg - print to dmesg output from check A-LUT entries.
*
* @alm: pointer to plx_a_lut_manager instance
* @pdev: The PCIe device
* @begin: first entry
* @begin: last entry - 1
*
* RETURNS: nothing
*/
static void plx_alm_entries_dmesg(struct plx_alm* alm, struct pci_dev* pdev,
	int begin, int num)
{
	unsigned int i;
	if (begin < 0) {
		begin = 0;
	}

	if (begin + num > alm->segments_num) {
		num = alm->segments_num - begin;
	}

	for (i = 0; i < num; i++) {
		int id = i + begin;
		dev_err(&pdev->dev, "[%02x] to:%016llx ref_cnt:%x start:%x segments_count:%x\n",
			/* ID */                id,
			/* to */                alm->entries[id].value,
			/* ref_cnt*/            alm->entries[id].counter,
			/* start */             alm->entries[id].start,
			/* segments_count */    alm->entries[id].segments_count);
	}
}

/*
* plx_alm_check - check A-LUT entries cohesion, use in debug check.
*
* @mngr: pointer to plx_a_lut_manager instance
* @pdev: The PCIe device
*
* RETURNS: not 0 if error
*/
static inline int plx_alm_check(struct plx_alm* alm, struct pci_dev* pdev)
{
	int err = 0;
	u32 i = 0;
	u32 j;
	u16 segments;
	while (i < alm->segments_num) {
		if (alm->entries[i].counter == 0) {
			/* Check empty entry */
			if (alm->entries[i].segments_count != 0 ||
				alm->entries[i].start != 0 || alm->entries[i].value != 0) {
				dev_err(&pdev->dev, "A-LUT: Invalid segment: [%02x]\n", i);
				plx_alm_entries_dmesg(alm, pdev, i, 1);
				err = -EINVAL;
			}
			++i;
			continue;
		}

		/* alm->entries[i].counter != 0 */
		/* Check group */
		segments = alm->entries[i].segments_count;

		if (segments == 0) {
			dev_err(&pdev->dev, "A-LUT: Invalid segment zero: [%02x]\n", i);
			plx_alm_entries_dmesg(alm, pdev, i, 1);
			err = -EINVAL;
			++i;
			continue;
		}

		if (segments + i > alm->segments_num) {
			dev_err(&pdev->dev, "A-LUT: Invalid segment too big: [%02x]\n", i);
			plx_alm_entries_dmesg(alm, pdev, i, segments);
			err = -EINVAL;
			++i;
			continue;
		}

		for (j = i; j < i + segments; ++j) {
			if (alm->entries[j].start != i ||
				((j != i) && (alm->entries[j].counter != 0 ||
					alm->entries[j].segments_count != 0))) {
				dev_err(&pdev->dev, "A-LUT: Detect Invalid block parent "
					"%02x: id: [%02x]\n", i, j);
				plx_alm_entries_dmesg(alm, pdev, i, segments);
				err = -EINVAL;
				break;
			}
		}
		i += segments;
	}
	BUG_ON(err != 0);
	return err;
}

/*
* plx_alm_init - Initialize a plx_a_lut_manager instance
(ie. allocates memory etc.)
*
* @mngr: pointer to plx_a_lut_manager instance
* @pdev: The PCIe device
* @num_ntbs: used to compute number of a-lut segments
* @aper_len: used to compute size of a signel a-lut segment
*
* RETURNS: 0 on success and -ENOMEM on failure
*/
int plx_alm_init(struct plx_alm* mngr,
	struct pci_dev *pdev, int segments_num, u64 aper_len)
{
	int rc = 0;

	mngr->segments_num = segments_num;
	mngr->segment_size = aper_len / mngr->segments_num;

	mngr->entries = (struct plx_alm_arr_entry*)kzalloc(
		sizeof(struct plx_alm_arr_entry) * mngr->segments_num, 0);

	if (!mngr->entries) {
		dev_info(&pdev->dev, "Could not allocate memory for a_lut_array!\n");
		rc = -ENOMEM;
	}

	dev_info(&pdev->dev,
		"A-LUT manager initialized!"
		"aper len: %llx, segments_num: %x, segment_size: %llx\n",
		aper_len, mngr->segments_num, mngr->segment_size);

#ifdef DEBUG_ALM_CHECK
	dev_err(&pdev->dev, "A-LUT manager DEBUG MODE: DEBUG_ALM_CHECK!\n");
#endif

	plx_alm_check(mngr, pdev);
	return rc;
}

/*
* plx_alm_release - releases plx_a_lut_manager instance
*
* @mngr: pointer to plx_a_lut_manager instance
*
* RETURNS: nothing
*/
void plx_alm_release(struct plx_alm* mngr, struct pci_dev *pdev)
{
	plx_alm_check(mngr, pdev);
	kfree(mngr->entries);
	mngr->segments_num = 0;
	mngr->segment_size = 0;
}

/*
* clear_entries - clear multiple entries in A-LUT array
*
* @records: pointer to A-LUT array
* @id_begin: first entry to be cleared
* @num: number entries to be cleared
*
* RETURNS: nothing
*/
static inline void clear_entries(struct plx_alm_arr_entry * entries,
	int id_begin, u32 num)
{
	memset(entries + id_begin, 0, sizeof(*entries) * num);
}

/*
* plx_alm_reset - clear A-LUT entries
*
* @mngr: pointer to plx_a_lut_manager instance
*
* RETURNS: nothing
*/
void plx_alm_reset(struct plx_alm* mngr, struct pci_dev *pdev)
{
	plx_alm_check(mngr, pdev);
	clear_entries(mngr->entries, 0, mngr->segments_num);
}

/**
* plx_alm_add_entry() - add entry to A-LUT array
* @mngr: pointer to plx_a_lut_manager instance
* @pdev: The PCIe device
* @addr: DMA address to access memory
* @size: size of allocation
*
* This function allows other side of NTB to access address @addr by adding
* a lookup entry to A LUT array.
*
* RETURNS:
* @out_segment_id: id of a segment in A-LUT array this
allocation is to be written
* @out_segments_num: number of continous segments to be written in A-LUT array
*
* */
int plx_alm_add_entry(struct plx_alm* mngr,
	struct pci_dev* pdev, dma_addr_t addr, size_t size,
	u32 *out_segment_id, u32 * out_segments_num)
{
	int i = 0;
	int rc = 0;

	u64 translation_mask = (u64)mngr->segment_size - 1;
	dma_addr_t addr_masked = addr & ~translation_mask;
	u64 offset_in_segment = addr & translation_mask;
	u32 segments = (u32)DIV_ROUND_UP(offset_in_segment + size,
		mngr->segment_size);
	u32 free_slots = 0;
	u32 match = -1;
	u64 idx = 0;

	PLX_ALM_CHECK(mngr, pdev);

	if (!size || size > mngr->segment_size * mngr->segments_num) {
		dev_err(&pdev->dev, "request for allocation %s\n",
			!size ? "with zero size" : "too big for translation");
		rc = -ENOMEM;
		goto finish;
	}

	while (i < mngr->segments_num) {
		idx = 0;

		/* check if there is enough of free consecutive blocks
		* to store this mapping */
		if (mngr->entries[i].counter == 0) {
			if (match == -1) {
				free_slots++;
				if (free_slots == segments)
					match = i - segments + 1;
			}
			i++;
		}
		else {
			free_slots = 0;

			/* we're in the first block of some mapping - check
			* if new mapping can be embedded into this one */
			if (addr_masked >= mngr->entries[i].value)
			{
				idx = (addr_masked - mngr->entries[i].value)
					/ mngr->segment_size;
				if (idx < mngr->segments_num &&
					idx + segments <=
					mngr->entries[i].segments_count) {
					match = i;
					break;
				}
				else {
					idx = 0;
				}
			}

			i += mngr->entries[i].segments_count;
		}
	}

	if (match != -1) {
		if (mngr->entries[match].counter == 0) {
			mngr->entries[match].value = addr_masked;
			mngr->entries[match].segments_count = segments;
			for (i = 0; i<segments; i++)
				mngr->entries[match + i].start = match;
		}
		else {
			rc = -EEXIST;
		}
	}
	else {

		dev_err(&pdev->dev, "out of A-LUT segments\n");
		rc = -ENOMEM;
		goto finish;
	}

	*out_segment_id = (u32)match + (u32)idx;
	*out_segments_num = segments;

finish:
	PLX_ALM_CHECK(mngr, pdev);
	return rc;
}

/**
* plx_alm_del_entry() - delete entry from A-LUT array
* @plx_a_lut_manager: pointer to plx_device instance
* @pdev: The PCIe device
* @segment_id: id of an A-LUT segment
*
* RETURNS:
* @out_segment_id: id of a starting segment,
from which we need to start clearing
* @out_segments_num: number of continous segments to be written in A-LUT array
*
* */
void plx_alm_del_entry(struct plx_alm* mngr, struct pci_dev* pdev, u32 segment_id,
	u32 * out_segment_id, u32 * out_segments_num)
{
	u32 start_id = mngr->entries[segment_id].start;

	PLX_ALM_CHECK(mngr, pdev);
	BUG_ON(mngr->entries[start_id].counter == 0);

	mngr->entries[start_id].counter--;

	if (mngr->entries[start_id].counter == 0) {
		u32 segments = mngr->entries[start_id].segments_count;

		*out_segment_id = start_id;
		*out_segments_num = segments;
		clear_entries(mngr->entries, start_id, segments);
	}
	PLX_ALM_CHECK(mngr, pdev);
}

static DECLARE_WAIT_QUEUE_HEAD(queue);
static volatile bool pollin;
static bool singleOpen = 0;
static struct proc_dir_entry *entry;

static unsigned int poll(struct file *file, poll_table* table)
{
	poll_wait(file, &queue, table);
	if (pollin)
	{
		pollin = 0;
		return POLLIN;

	}
	return 0;
}

static int open(struct inode *inode, struct file *file)
{
	if (!singleOpen)
	{
		singleOpen = true;
		return 0;
	}
	return -EBUSY;
}

static int release(struct inode* i, struct file* f)
{
	singleOpen = false;
	return 0;
}

static const struct file_operations os_reboot =
{
	.owner = THIS_MODULE,
	.open = open,
	.poll = poll,
	.release = release
};

void plx_reboot_notify()
{
	pollin = POLLIN;
	wake_up(&queue);
}

void plx_exit_procfs(void)
{
	remove_proc_entry("vca_os_reboot", entry);
}

static int __init plx_init(void)
{
	int ret = 0;

	ida_init(&g_plx_ida);

	ret = pci_register_driver(&plx_driver);
	if (ret) {
		pr_err("pci_register_driver failed ret %d\n", ret);
		goto cleanup_debugfs;
	}
	return ret;
cleanup_debugfs:
	ida_destroy(&g_plx_ida);
	plx_exit_procfs();
	return ret;
}

module_init(plx_init);
module_exit(plx_exit);

MODULE_AUTHOR("Intel Corporation");
MODULE_DESCRIPTION("Intel(R) PLX87XX VCA PCIe driver");
MODULE_LICENSE("GPL v2");
